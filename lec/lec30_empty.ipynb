{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plots\n",
    "plots.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lecture, I am going to use more interactive plots (they look better) so I am using the plotly.express library.  We won't test you on this but it's good to know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 30\n",
    "\n",
    "In this lecture, we derive the equation for linear regression using the correlation coefficient $r$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap From Last Lecture\n",
    "\n",
    "In the previous lecture, we introduced the correlation coefficient: \n",
    "\n",
    "\\begin{align}\n",
    "r \n",
    "& = \\text{Mean}\\left(\\text{StandardUnits}(x) *  \\text{StandardUnits}(y)\\right)\\\\\n",
    "& = \\frac{1}{n} \\sum_{i=1}^n \\text{StandardUnits}(x_i) *  \\text{StandardUnits}(y_i)\\\\\n",
    "& = \\frac{1}{n}\\sum_{i=1}^n \\left( \\frac{x_i - \\text{Mean}(x)}{\\text{Stdev}(x)} \\right) * \\left( \\frac{y_i - \\text{Mean}(y)}{\\text{Stdev}(y)} \\right) \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implemented the correlation coefficient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_units(x):\n",
    "    \"Convert any array of numbers to standard units.\"\n",
    "    return (x - np.average(x)) / np.std(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(t, x, y):\n",
    "    \"\"\"t is a table; x and y are column labels\"\"\"\n",
    "    x_in_su = standard_units(t.column(x))\n",
    "    y_in_su = standard_units(t.column(y))\n",
    "    return np.mean(x_in_su * y_in_su)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We built an intuition about the correlation coefficient using the following code which you don't need to understand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_correlated_data(r, n=500):\n",
    "    \"Generate a a table with columns x and y with a correlation of approximately r\"\n",
    "    x = np.random.normal(0, 1, n)\n",
    "    z = np.random.normal(0, 1, n)\n",
    "    # This is \"magic\" to sample from a multivariate Gaussian\n",
    "    y = r*x + (np.sqrt(1-r**2))*z \n",
    "    return Table().with_columns(\"x\", x, \"y\", y)\n",
    "\n",
    "def r_scatter(r, n=500, subplot=False):\n",
    "    \"Generate a scatter plot with a correlation approximately r\"\n",
    "    data = make_correlated_data(r, n)\n",
    "    plt = go.Scatter(x=data.column(\"x\"), y= data.column(\"y\"), \n",
    "                     name=str(r), mode=\"markers\", marker_opacity=0.5)\n",
    "    if subplot:\n",
    "        return plt\n",
    "    else: \n",
    "        return go.Figure().add_trace(plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs = make_subplots(2,3)\n",
    "n=500\n",
    "figs.add_trace(r_scatter(0.2,  n, subplot=True), 1, 1)\n",
    "figs.add_trace(r_scatter(0.5,  n, subplot=True), 1, 2)\n",
    "figs.add_trace(r_scatter(0.8,  n, subplot=True), 1, 3)\n",
    "figs.add_trace(r_scatter(-0.2, n, subplot=True), 2, 1)\n",
    "figs.add_trace(r_scatter(-0.5, n, subplot=True), 2, 2)\n",
    "figs.add_trace(r_scatter(-0.8, n, subplot=True), 2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "---\n",
    "\n",
    "<center>Return to Slides</center>\n",
    "\n",
    "---\n",
    "\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Care when Interpreting the Correlation\n",
    "\n",
    "When computing correlation it is important to always visualize your data first and then consider each of the following issues.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "### Correlation does Not Imply Causation\n",
    "\n",
    "We have covered this one extensively at this point.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "\n",
    "### Nonlinearity\n",
    "\n",
    "Low correlation does not imply absence of a relationship. Correlation measures linear relationships.  Data with strong non-linear relationship may have very low correlation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x = np.arange(-4, 4.1, 0.5)\n",
    "nonlinear = Table().with_columns(\n",
    "        'x', new_x,\n",
    "        'y', new_x**2\n",
    "    )\n",
    "nonlinear.iscatter('x', 'y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is clearly a relationship to this data.  Given the value of $x$ you can easily predict the value of $y$.  What is the correlation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(nonlinear, 'x', 'y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "### Outliers\n",
    "\n",
    "Outliers can have a significant effect on correlation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = Table().with_columns(\n",
    "        'x', make_array(1, 2, 3, 4),\n",
    "        'y', make_array(1, 2, 3, 4)\n",
    "    )\n",
    "line.iscatter('x', 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(line, 'x', 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier = Table().with_columns(\n",
    "        'x', make_array(1, 2, 3, 4, 5),\n",
    "        'y', make_array(1, 2, 3, 4, 0)\n",
    "    )\n",
    "outlier.iscatter('x', 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(outlier, 'x', 'y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "### Ecological Correlations\n",
    "\n",
    "The correlation between aggregated variables (e.g., after grouping) may be much higher than the correlation between the underlying variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat2014 = Table.read_table('sat2014.csv').sort('State')\n",
    "sat2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat2014.iscatter('Critical Reading', 'Math')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(sat2014, 'Critical Reading', 'Math')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is a very strong correlation.  However, each data point corresponds to a large cloud of data points where each person might have had greater variability in their scores.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "\n",
    "### Bonus: Understanding the SAT data\n",
    "While we have the data loaded.  Does anyone have a guess which dots correspond to which state?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "px.scatter(sat2014.to_df(), \n",
    "           x = \"Critical Reading\",\n",
    "           y = \"Math\",\n",
    "           hover_name = \"State\",\n",
    "           size = \"Participation Rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "---\n",
    "\n",
    "<center>Return to Slides</center>\n",
    "\n",
    "---\n",
    "\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Lines\n",
    "\n",
    "Here we build an intuition about the relationship between the slope of the nearest neighbor line and the correlation coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Using the Heights Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the family height data\n",
    "families = Table.read_table('family_heights.csv')\n",
    "parent_avgs = (families.column('father') + families.column('mother'))/2\n",
    "heights = Table().with_columns(\n",
    "    'Parent Average', parent_avgs,\n",
    "    'Child', families.column('child'),\n",
    ").sort(\"Parent Average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a slightly more robust Nearest Neighbor predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_heights(parent_average, window=0.5):\n",
    "    lower_bound = parent_average - window\n",
    "    upper_bound = parent_average + window\n",
    "    similar_child_heights = (\n",
    "        heights\n",
    "            .where(\"Parent Average\", are.between(lower_bound, upper_bound))\n",
    "            .column(\"Child\")\n",
    "    )\n",
    "    if len(similar_child_heights) == 0: #handle the case when there is no data\n",
    "        return np.nan # nan = not a number , a special floating point \"number\"\n",
    "    else:\n",
    "        return np.mean(similar_child_heights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions at many different parent heights not just the heights in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_heights = Table().with_column(\"Parent Average\", np.arange(61,74,0.2))\n",
    "test_heights = test_heights.with_column(\n",
    "    \"NN Prediction\", test_heights.apply(nn_heights, \"Parent Average\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot it all\n",
    "fig = px.scatter(heights.to_df(), x=\"Parent Average\", y=\"Child\", height=600)\n",
    "fig.add_scatter(x=test_heights.column(\"Parent Average\"), \n",
    "                y=test_heights.column(\"NN Prediction\"), name=\"NN Prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it will be easier to start in standard units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transform the heights data into standard units\n",
    "su_heights = Table().with_columns(\n",
    "    \"Parent Average\", standard_units(heights.column(\"Parent Average\")),\n",
    "    \"Child\", standard_units(heights.column(\"Child\")))\n",
    "\n",
    "## Transform the nearest neighbor predictions to standard units\n",
    "su_test_heights = Table().with_columns(\n",
    "    \"Parent Average\", \n",
    "    (test_heights.column(\"Parent Average\") - heights.column(\"Parent Average\").mean()) \n",
    "                        / heights.column(\"Parent Average\").std(),\n",
    "    \"NN Prediction\", \n",
    "    (test_heights.column(\"NN Prediction\") - heights.column(\"Child\").mean()) \n",
    "                        / heights.column(\"Child\").std()) \n",
    "\n",
    "## Plot it all\n",
    "fig = px.scatter(su_heights.to_df(), x=\"Parent Average\", y=\"Child\", height=600)\n",
    "fig.add_scatter(x=su_test_heights.column(\"Parent Average\"), \n",
    "                y=su_test_heights.column(\"NN Prediction\"), name=\"NN Prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the correlation we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(heights, \"Parent Average\", \"Child\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we draw a line with that slope:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = correlation(su_heights, \"Parent Average\", \"Child\")\n",
    "fig = px.scatter(su_heights.to_df(), x=\"Parent Average\", y=\"Child\", height=600)\n",
    "fig.add_scatter(x=su_test_heights.column(\"Parent Average\"), \n",
    "                y=su_test_heights.column(\"NN Prediction\"), \n",
    "                name=\"NN Prediction\")\n",
    "fig.add_scatter(x=np.arange(-3,4,0.1), y= r * np.arange(-3,4,0.1), \n",
    "                name=f\"Line(y={np.round(r,4)} x)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Relationship Between Correlation and NN Predictions\n",
    "\n",
    "Here we examine the relationship between the nearest neighbor prediction \"line\" and the correlation for several synthetic datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You don't need to understand all the parts of this function.\n",
    "def make_correlation_and_line_plot(r):\n",
    "    \"\"\" \n",
    "    Generates a plot of synthetic data with a correlation coefficient r\n",
    "    along with the nearest neighbor predictions and \n",
    "    a line with the slope r and intercept 0\n",
    "    \"\"\"\n",
    "    # Make synthetic data\n",
    "    example = make_correlated_data(r).sort(\"x\")\n",
    "    \n",
    "    # Compute nearest neighbor predictions\n",
    "    def nn_prediction_example(x_val):\n",
    "        \"\"\" Predicts y-value for x based on the example table \"\"\"\n",
    "        neighbors = example.where('x', are.between(x_val - .25, x_val + .25)).column(\"y\")\n",
    "        if len(neighbors) == 0:\n",
    "            return np.nan\n",
    "        else: \n",
    "            return np.mean(neighbors)   \n",
    "    example = example.with_columns(\n",
    "        'NN Prediction', example.apply(nn_prediction_example, 'x'))\n",
    "    \n",
    "    # Generate Plots.\n",
    "    x,y = example.column(\"x\"), example.column(\"y\")\n",
    "    fig = px.scatter(example.to_df(), x=\"x\", y=\"y\", height=600)\n",
    "    fig.add_scatter(x=example.column(\"x\"), y=example.column(\"NN Prediction\"), \n",
    "                    name=\"NN Prediction\")\n",
    "    fig.add_scatter(x=x, y= r * x, name=f\"Line(y={r} x)\")\n",
    "    fig.add_scatter(x=x, y=x, line_color=\"gray\", line_dash=\"dot\", name=\"Line(y=x)\")\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation of 0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_correlation_and_line_plot(r=0.90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation of 0.60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_correlation_and_line_plot(r=0.60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation of 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_correlation_and_line_plot(r=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation of 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_correlation_and_line_plot(r=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation of -0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_correlation_and_line_plot(r=-0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "---\n",
    "\n",
    "<center>Return to Slides</center>\n",
    "\n",
    "---\n",
    "\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the linear regression line\n",
    "\n",
    "In standard units we developed a simple equation for the regression line:\n",
    "\n",
    "\\begin{align}\n",
    "\\text{SU}(y_\\text{predicted}) = r * \\text{SU}(x_\\text{new})\n",
    "\\end{align}\n",
    "\n",
    "where $r$ is the correlation coefficient and $\\text{SU}$ is the standard units:\n",
    "\n",
    "\\begin{align}\n",
    "\\text{SU}(y_\\text{predicted}) & = \\frac{y_\\text{predicted} - \\text{Mean}(y)}{\\text{Stdev}(y)} \\\\\n",
    "\\text{SU}(x_\\text{new}) &= \\frac{x_\\text{new} - \\text{Mean}(x)}{\\text{Stdev}(x)}\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "\n",
    "Here we use $x_\\text{new}$ to indicate a new $x$ value for which we want to make a prediction  $y_\\text{predicted}$.\n",
    "\n",
    "We would like to express this line in the original units of the data.  We can do that by substituting the definition of standard units:\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{y_\\text{predicted} - \\text{Mean}(y)}{\\text{Stdev}(y)} = r *  \\frac{x_\\text{new} - \\text{Mean}(x)}{\\text{Stdev}(x)}\n",
    "\\end{align}\n",
    "\n",
    "While this equation does desribe a line it would look a little nicer in the form:\n",
    "\n",
    "\\begin{align}\n",
    "y_\\text{predicted} = \\text{slope} * x_\\text{new}  + \\text{intercept}\n",
    "\\end{align}\n",
    "\n",
    "Let's do some algebra to get that equation:\n",
    "$$\n",
    "\\require{color}\n",
    "\\definecolor{comment}{RGB}{200,100,50}\n",
    "\\begin{align}\n",
    "\\frac{y_\\text{predicted} - \\text{Mean}(y)}{\\text{Stdev}(y)} &= r *  \\frac{x_\\text{new} - \\text{Mean}(x)}{\\text{Stdev}(x)}\\\\\n",
    "\\frac{y_\\text{predicted} - \\text{Mean}(y)}{\\text{Stdev}(y)} &= r * \\frac{1}{\\text{Stdev}(x)} x_\\text{new} - r * \\frac{1}{\\text{Stdev}(x)}\\text{Mean}(x)  & \\color{comment} \\text{Expanding the right side}\\\\\n",
    "y_\\text{predicted} - \\text{Mean}(y) &= r * \\frac{\\text{Stdev}(y)}{\\text{Stdev}(x)} x_\\text{new} - r * \\frac{\\text{Stdev}(y)}{\\text{Stdev}(x)}\\text{Mean}(x) &  \\color{comment} \\text{Multiplying by $\\text{Stdev}(y)$}\\\\\n",
    "y_\\text{predicted} &= r * \\frac{\\text{Stdev}(y)}{\\text{Stdev}(x)} x_\\text{new} + \\text{Mean}(y) - r * \\frac{\\text{Stdev}(y)}{\\text{Stdev}(x)}\\text{Mean}(x) &  \\color{comment} \\text{Adding $\\text{Mean}(y)$}\\\\\n",
    "y_\\text{predicted} &= \\left(r * \\frac{\\text{Stdev}(y)}{\\text{Stdev}(x)}\\right) x_\\text{new} + \\left(\\text{Mean}(y) - r * \\frac{\\text{Stdev}(y)}{\\text{Stdev}(x)}\\text{Mean}(x)\\right) &  \\color{comment} \\text{Rearranging Terms}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "This means we can define the slope and intercept as:\n",
    "\\begin{align}\n",
    "\\text{slope} &= r * \\frac{\\text{Stdev}(y)}{\\text{Stdev}(x)}\\\\\n",
    "\\text{intercept} & = \\text{Mean}(y) - \\text{slope} * \\text{Mean}(x)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "## Implementing Linear Regression\n",
    "\n",
    "Using the above equations implement the slope and intercept functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slope(t, x, y):\n",
    "    \"\"\"Computes the slope of the regression line\"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><details><br>\n",
    "    \n",
    "```python\n",
    "def slope(t, x, y):\n",
    "    \"\"\"Computes the slope of the regression line\"\"\"\n",
    "    r = correlation(t, x, y)\n",
    "    y_sd = np.std(t.column(y))\n",
    "    x_sd = np.std(t.column(x))\n",
    "    return r * y_sd / x_sd\n",
    "```\n",
    "\n",
    "<br></details><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intercept(t, x, y):\n",
    "    \"\"\"Computes the intercept of the regression line\"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><details><br>\n",
    "    \n",
    "```python\n",
    "def intercept(t, x, y):\n",
    "    \"\"\"Computes the intercept of the regression line\"\"\"\n",
    "    x_mean = np.mean(t.column(x))\n",
    "    y_mean = np.mean(t.column(y))\n",
    "    return y_mean - slope(t, x, y)*x_mean\n",
    "```\n",
    "\n",
    "<br></details><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = make_correlated_data(0.5)\n",
    "slope(example, 'x', 'y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the slope and intercept for the heights dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_slope = ...\n",
    "heights_intercept = ...\n",
    "[heights_slope, heights_intercept]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><details><br>\n",
    "    \n",
    "```python\n",
    "heights_slope = slope(heights, 'Parent Average', 'Child')\n",
    "heights_intercept = intercept(heights, 'Parent Average', 'Child')\n",
    "[heights_slope, heights_intercept]\n",
    "```\n",
    "\n",
    "<br></details><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the regression predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights = heights.with_column(\n",
    "    'Regression Prediction', \n",
    "    ...\n",
    ")\n",
    "heights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><details><br>\n",
    "    \n",
    "```python\n",
    "heights = heights.with_column(\n",
    "    'Regression Prediction', \n",
    "    predicted_heights_slope*heights.column('Parent Average') + predicted_heights_intercept\n",
    ")\n",
    "heights\n",
    "```\n",
    "\n",
    "<br></details><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(heights.to_df(), x=\"Parent Average\", y=\"Child\", height=600)\n",
    "fig.add_scatter(x=test_heights.column(\"Parent Average\"), \n",
    "                y=test_heights.column(\"NN Prediction\"), name=\"NN Prediction\")\n",
    "line_name = f\"y = {np.round(heights_slope,2)} x + {np.round(heights_intercept,2)}\"\n",
    "fig.add_scatter(x=heights.column(\"Parent Average\"), \n",
    "                y=heights.column(\"Regression Prediction\"),\n",
    "                name=line_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "---\n",
    "\n",
    "<center>Return to Slides</center>\n",
    "\n",
    "---\n",
    "\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion Question: Exam Score Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X-axis: midterm scores\n",
    "midterm_mean = 70\n",
    "midterm_sd = 10\n",
    "\n",
    "# Y-axis: final scores\n",
    "final_mean = 50\n",
    "final_sd = 12\n",
    "\n",
    "# Correlation (relates X to Y values)\n",
    "corr = 0.75\n",
    "\n",
    "# X value\n",
    "midterm_student = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midterm_student_su = (midterm_student - midterm_mean) / midterm_sd\n",
    "midterm_student_su"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_student_su = midterm_student_su * corr\n",
    "final_student_su"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_student = final_student_su * final_sd + final_mean\n",
    "final_student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
